{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import math as m\n",
    "import pickle\n",
    "from kernel3d import kernel3d\n",
    "from tal2icbm_spm import tal2icbm_spm\n",
    "\n",
    "cwd = os.getcwd()\n",
    "raw_folder = cwd + \"/DataRaw\"\n",
    "mask_folder = cwd + \"/MaskenEtc\"\n",
    "\n",
    "df = pd.read_excel(raw_folder + \"/Stroop_Updatejune2020_CWvsother_compareCundN.xlsx\", engine='openpyxl')\n",
    "\n",
    "template = nb.load(mask_folder + \"/Grey10.nii\")\n",
    "template_shape = template.get_fdata().shape\n",
    "x_max = template_shape[0]\n",
    "y_max = template_shape[1]\n",
    "z_max = template_shape[2]\n",
    "\n",
    "lines_columns = [\"Author\", \"Subjects\", \"XYZmm\", \"Space\", \"Cond\", \"ExpIndex\"]\n",
    "lines = pd.DataFrame(columns=lines_columns)\n",
    "exp_columns = [\"Author\", \"Subjects\", \"Space\", \"Cond\", \"XYZmm\", \"UncertainTemplates\",\n",
    "               \"UncertainSubjects\", \"Smoothing\", \"XYZ\", \"Kernel\", \"Peaks\"]\n",
    "experiments = pd.DataFrame(columns=exp_columns)\n",
    "\n",
    "df = df[df['Articles'].notnull()].reset_index(drop=True)\n",
    "\n",
    "cnt_exp = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    lines.at[index, \"Author\"] = row.Articles\n",
    "    lines.at[index, \"Subjects\"] = int(row.Subjects)\n",
    "    lines.at[index, \"XYZmm\"] = row.x, row.y, row.z\n",
    "    lines.at[index, \"Space\"] = row[5]\n",
    "    lines.at[index, \"Cond\"] = list(row[6:].dropna().str.lower().str.strip().values)\n",
    "\n",
    "    \n",
    "    if index > 0:\n",
    "        cnt_exp += 1\n",
    "        if (lines.loc[index, [\"Author\", \"Subjects\"]] == lines.loc[index-1, [\"Author\", \"Subjects\"]]).all():\n",
    "            if set(lines.at[index, \"Cond\"]) == set(lines.at[index-1, \"Cond\"]):\n",
    "                cnt_exp -= 1\n",
    "            \n",
    "    lines.at[index, \"ExpIndex\"] = cnt_exp\n",
    "\n",
    "for i in range(lines.iloc[-1][\"ExpIndex\"] + 1):\n",
    "    start = lines[lines[\"ExpIndex\"] == i].index[0]\n",
    "    experiments.at[i,\"Author\"] = lines.at[start, \"Author\"]\n",
    "    experiments.at[i,\"Subjects\"] = lines.at[start, \"Subjects\"]\n",
    "    experiments.at[i,\"Space\"] = lines.at[start, \"Space\"]\n",
    "    experiments.at[i,\"Cond\"] = lines.at[start, \"Cond\"]\n",
    "    \n",
    "    experiments.at[i,\"XYZmm\"] = np.vstack(lines[lines[\"ExpIndex\"] == i].XYZmm).T.astype(float)\n",
    "    \n",
    "    if experiments.at[i, 'Space'] == 'TAL':\n",
    "        experiments.at[i, 'XYZmm'] = tal2icbm_spm(experiments.at[i, 'XYZmm'])\n",
    "    \n",
    "    experiments.at[i,\"UncertainTemplates\"] = (5.7/(2*m.sqrt(2/m.pi)) * m.sqrt(8*m.log(2)))\n",
    "    experiments.at[i, \"UncertainSubjects\"] =  (11.6/(2*m.sqrt(2/m.pi)) * m.sqrt(8*m.log(2))) / m.sqrt(lines.at[start, \"Subjects\"])\n",
    "    experiments.at[i, \"Smoothing\"] = m.sqrt(experiments.at[i,\"UncertainTemplates\"]**2 + experiments.at[i, \"UncertainSubjects\"]**2)\n",
    "    \n",
    "    experiments.at[i, \"XYZ\"] = np.round(np.dot(np.linalg.inv(template.affine),\n",
    "                                      np.concatenate((experiments.at[i, \"XYZmm\"],\n",
    "                                                      np.ones((1,experiments.at[i, \"XYZmm\"].shape[1])))))).astype(int)\n",
    "    experiments.at[i, \"XYZ\"][0][experiments.at[i, \"XYZ\"][0] >= x_max] = x_max-1\n",
    "    experiments.at[i, \"XYZ\"][1][experiments.at[i, \"XYZ\"][1] >= x_max] = y_max-1\n",
    "    experiments.at[i, \"XYZ\"][2][experiments.at[i, \"XYZ\"][2] >= x_max] = z_max-1    \n",
    "    experiments.at[i, \"XYZ\"][experiments.at[i, \"XYZ\"] < 1] = 1\n",
    "    \n",
    "    experiments.at[i, 'Kernel'] = kernel3d(template.affine, experiments.at[i, 'Smoothing'], 31)\n",
    "    experiments.at[i, \"Peaks\"] = experiments.at[i, \"XYZ\"].shape[1]\n",
    "    \n",
    "\n",
    "task_names, task_counts = np.unique(np.hstack(experiments.Cond), return_counts=True)\n",
    "\n",
    "tasks_columns = [\"Name\", \"Num_Exp\", \"Who\", \"TotalSubjects\", \"ExpIndex\"]\n",
    "tasks = pd.DataFrame(columns=tasks_columns)\n",
    "tasks.Name = np.append(task_names, \"all\")\n",
    "tasks.Num_Exp = np.append(task_counts, experiments.shape[0])\n",
    "\n",
    "for task_row, value in enumerate(list(tasks.Name)):\n",
    "    counter = 0\n",
    "    for exp_row in range(lines.iloc[-1][\"ExpIndex\"] + 1):\n",
    "        if value in experiments.at[exp_row, \"Cond\"]:\n",
    "            if counter == 0:\n",
    "                tasks.at[task_row, \"Who\"] = [experiments.at[exp_row, \"Author\"]]\n",
    "                tasks.at[task_row, \"TotalSubjects\"] = experiments.at[exp_row, \"Subjects\"]\n",
    "                tasks.at[task_row, \"ExpIndex\"] = [exp_row]\n",
    "            else:\n",
    "                tasks.at[task_row, \"Who\"].append(experiments.at[exp_row, \"Author\"])\n",
    "                tasks.at[task_row, \"TotalSubjects\"] += experiments.at[exp_row, \"Subjects\"]\n",
    "                tasks.at[task_row, \"ExpIndex\"].append(exp_row)\n",
    "            counter += 1\n",
    "    \n",
    "\n",
    "tasks.at[tasks.index[-1], \"Who\"] = experiments.Author.to_list()\n",
    "tasks.at[tasks.index[-1], \"TotalSubjects\"] = sum(experiments.Subjects.to_list())\n",
    "tasks.at[tasks.index[-1], \"ExpIndex\"] = list(range(experiments.shape[0]))\n",
    "\n",
    "tasks = tasks.sort_values(by=\"Num_Exp\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "pickle_object = (experiments, tasks)\n",
    "if not os.path.exists(cwd+\"/DataPickle\"):\n",
    "    os.makedirs(cwd+\"/DataPickle\")\n",
    "with open(cwd+\"/DataPickle/data.pickle\", \"wb\") as f:\n",
    "    pickle.dump(pickle_object, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
