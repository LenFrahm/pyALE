{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gross-falls",
   "metadata": {},
   "source": [
    "# ALE\n",
    "\n",
    "This notebook will guide you through the process of setting up and running an ALE meta-analysis.\n",
    "\n",
    "First we need to set up two excel files that will serve as input for all following steps:\n",
    "\n",
    "#### 1. Experiment information\n",
    "\n",
    "Please use the following format / syntax:\n",
    "\n",
    "- The spreadsheet should have a title row that will not be read\n",
    "- The order of the columns should be as in this example\n",
    "- Tags are optional\n",
    "- At the moment numeric tags are not working!\n",
    "\n",
    "![title](img/exp_info.png)\n",
    "\n",
    "**Important note: In either case the tags are taken straight as they are, so please make sure that spelling (including spaces etc) is consistent throughout the file!**\n",
    "\n",
    "\n",
    "#### 2. Analysis information\n",
    "\n",
    "Please use the following format / syntax:\n",
    "\n",
    "![title](img/meta_info.png)\n",
    "\n",
    "**1st column**: \n",
    "- M denotes main effect\n",
    "- P denotes probabilistic / subsampled / CV'd ALE\n",
    "    - Need to specify the desired N after the P, e.g. P17\n",
    "- C denotes contrast (this line and the following are contrasted against each other). If the respective main effects in the two lines [e.g. 3 and 4] are not yet computed, they will be evaluated\n",
    "- B denotes balanced contrast. This way both analysis will be based on the same N. (Option to specify the desired N after the B, e.g. B17)\n",
    "    - Option to specify the desired N after the B, e.g. B17. If no N is provided N will be equal to the smaller analysis N - 2 or the mean between the smaller analysis N and 17 depending on which is smaller.\n",
    "\n",
    "**2nd column**:\n",
    "Titel of the effect. Ideally avoid spaces and non file-name characters. When (re-) entering a title as part of a contrast, please keep naming/spelling consistent otherwise the “old” main effect is not recognized\n",
    "\n",
    "**3rd column onwards: Specify the analysis by tags.**\n",
    "- +ALL   ->   Include the entire set of experiments in that matfile\n",
    "- +Tag   ->    Include only those experiments that have the respective label\n",
    "- +Tag1  +Tag2   -> Conjunction, includes only experiments that have both labels\n",
    "- +Tag1  +Tag2   ?   ->  Logical ‘OR’, includes experiments that have either label\n",
    "- -Tag   ->   Exclude experiments that have the respective label\n",
    "- $VOI   ->  additionally to the voxel-wise analysis perform VOI analysis for the specified VOI [full path/filename, binary mask]. Multiple VOIs can be entered after each other and are evaluated at the same time. Furthermore an atlas can be added and a ROI analysis will be run for each distinct region specified in the atlas\n",
    "\n",
    "## How to run your analyses\n",
    "\n",
    "1. Create a folder in which you would like to run your analysis (can be the folder you cloned this repository to)\n",
    "2. Copy both excel sheets into the folder\n",
    "3. Enter the path to your folder and the names of your two excel sheets into the code cell below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "global-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/lennart/Code/lennoir/\"\n",
    "analysis_info_name = \"analysis_info_all.xlsx\"\n",
    "experiment_info_name = \"experiment_info_all.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-millennium",
   "metadata": {
    "tags": []
   },
   "source": [
    "4. Run your analysis by running the code cells below. There will be output printed below indicating your process.\n",
    " \n",
    "**Attention: Depending on your knowledge level you can either run the basic routine taking over all default parameter values or run the advanced routine, where you can change the parameter settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deadly-genius",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lennart/.pyenv/versions/pyALE/lib/python3.8/site-packages/nilearn/datasets/__init__.py:93: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "from nb_pipeline import setup, analysis\n",
    "meta_df, exp_all, tasks = setup(path, analysis_info_name, experiment_info_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-width",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Basic routine\"\"\"\n",
    "analysis(wd, meta_df, exp_all, tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "descending-groove",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter main\n",
      "Insomnia_all_aberrant : 28 experiments; average of 31.14 subjects per experiment\n",
      "Insomnia_all_aberrant - illustrate Foci\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lennart/.pyenv/versions/pyALE/lib/python3.8/site-packages/nilearn/plotting/img_plotting.py:341: FutureWarning: Default resolution of the MNI template will change from 2mm to 1mm in version 0.10.0\n",
      "  anat_img = load_mni152_template()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insomnia_all_aberrant - computing ALE and null PDF\n",
      "Insomnia_all_aberrant - computing p-values & TFCE\n",
      "Insomnia_all_aberrant - simulating null\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=6)]: Done 1000 out of 1000 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insomnia_all_aberrant - inference and printing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lennart/.pyenv/versions/pyALE/lib/python3.8/site-packages/nilearn/plotting/find_cuts.py:66: UserWarning: Given img is empty. Returning default cut_coords=(0.0, 0.0, 0.0) instead.\n",
      "  warnings.warn(\n",
      "/home/lennart/.pyenv/versions/pyALE/lib/python3.8/site-packages/nilearn/plotting/displays.py:880: UserWarning: empty mask\n",
      "  get_mask_bounds(new_img_like(img, not_mask, affine))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min p-value for FWE:1.0\n",
      "Min p-value for cFWE:0.031\n",
      "Insomnia_all_aberrant - done!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Advanced Routine\"\"\"\n",
    "\n",
    "# if TFCE should be included in the main effect analysis. very computationally expensive and does not give big benefits over cFWE.\n",
    "tfce_enabled=False\n",
    "\n",
    "# number of processes spawned when parallelizing. ideally should not exceed the amount of cores of the machine.\n",
    "nprocesses=6\n",
    "\n",
    "# amount of reptitions used for null distribution simulation (noise samples). Convergence starts at around 1000, recommended value = 10000\n",
    "# Used in all types of analysis\n",
    "null_repeats=1000\n",
    "\n",
    "# significance threshold used for cluster forming. recommended value = 0.001\n",
    "# Used in full MainEffect analysis\n",
    "cluster_thresh=0.001\n",
    "\n",
    "# Amount of samples taken from study population, recommended value = 2500\n",
    "# Used in probabilistic and balanced contrast\n",
    "sample_n=2500\n",
    "\n",
    "# Threshold used to compare differences against. recommended value = 0.05\n",
    "# Used in (\"legacy\") contrast\n",
    "diff_thresh=0.05\n",
    "\n",
    "# Whether or not the contrast is only calculated in areas, which are significant in the main_effect analysis\n",
    "# Used in (\"legacy\") contrast\n",
    "masking=False\n",
    "\n",
    "# Amount of sampling repititions used when comparing two subsampled ALEs. recommended value > 500\n",
    "# Used in balanced contrast\n",
    "# Note: As this difference permutation is performed inside of the null distribution simulation it gets repeated X (null_repeats) amount of times\n",
    "# - this can lead to a small increase in diff_repeats leading to a big increase in computation time\n",
    "diff_repeats=300\n",
    "\n",
    "analysis(path = path,\n",
    "         meta_df = meta_df,\n",
    "         exp_all = exp_all,\n",
    "         tasks = tasks,\n",
    "         tfce_enabled = tfce_enabled,\n",
    "         null_repeats = null_repeats,\n",
    "         cluster_thresh = cluster_thresh,\n",
    "         sample_n = sample_n,\n",
    "         diff_thresh = diff_thresh,\n",
    "         masking = masking,\n",
    "         diff_repeats = diff_repeats,\n",
    "         nprocesses = nprocesses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
