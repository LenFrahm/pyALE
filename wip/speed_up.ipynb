{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tracked-daniel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lfrahm/.pyenv/versions/3.9.1/envs/pyALE/lib/python3.9/site-packages/nilearn/datasets/__init__.py:87: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isfile, isdir\n",
    "from tkinter import filedialog\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from main_effect import main_effect\n",
    "from contrast import contrast\n",
    "from legacy_contrast import legacy_contrast\n",
    "import compile_studies\n",
    "from contribution import contribution\n",
    "from folder_setup import folder_setup\n",
    "from roi import check_rois\n",
    "from read_exp_info import read_exp_info\n",
    "from compute import *\n",
    "from template import pad_shape\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#cwd = filedialog.askdirectory(title=\"Select analysis folder\")\n",
    "cwd = os.getcwd()\n",
    "meta_df = pd.read_excel(f\"{cwd}/DataRaw/Test.xlsx\", engine='openpyxl', header=None)\n",
    "\n",
    "if not isdir(\"Results\"):\n",
    "    folder_setup(cwd)\n",
    "\n",
    "if isfile(f'{cwd}/Results/experiments.pickle'):\n",
    "    with open(f'{cwd}/Results/experiments.pickle', 'rb') as f:\n",
    "        exp_all, tasks = pickle.load(f)\n",
    "else:\n",
    "    exp_all, tasks = read_exp_info(f'{cwd}/DataRaw/Stroop_Updatejune2020_CWvsother_compareCundN.xlsx')\n",
    "\n",
    "row_idx = 0\n",
    "exp_name = meta_df.iloc[row_idx, 1]\n",
    "exp_idxs, masks, mask_names = compile_studies.from_excel(meta_df, row_idx, tasks)\n",
    "exp_df = exp_all.loc[exp_idxs].reset_index(drop=True)\n",
    "\n",
    "num_peaks = exp_df.Peaks\n",
    "\n",
    "bin_steps=0.0001\n",
    "cluster_thresh=0.001\n",
    "s0 = list(range(exp_df.shape[0]))\n",
    "# highest possible ale value if every study had a peak at the same location.\n",
    "mb = 1\n",
    "for i in s0:\n",
    "    mb = mb*(1-np.max(exp_df.at[i, 'Kernels']))\n",
    "\n",
    "# define bins for histogram\n",
    "bin_edges = np.arange(0.00005,1-mb+0.001,bin_steps)\n",
    "bin_centers = np.arange(0,1-mb+0.001,bin_steps)\n",
    "step = int(1/bin_steps)\n",
    "\n",
    "peaks = np.array([exp_df.XYZ[i].T for i in s0], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "official-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = np.array([exp_df.MA.values[i] for i in s0])\n",
    "hx = compute_hx(s0, ma, bin_edges)\n",
    "ale = compute_ale(ma)\n",
    "hx_conv = compute_hx_conv(s0, hx, bin_centers, step)\n",
    "z = compute_z(ale, hx_conv, step)\n",
    "tfce = compute_tfce(z, sample_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "western-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "clean-premises",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.829862648999999\n"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "from mytime import tic, toc\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import nibabel as nb\n",
    "cimport numpy as np\n",
    "from libcpp cimport bool\n",
    "\n",
    "\n",
    "cdef float E=0.6\n",
    "cdef int H=2\n",
    "cdef float dh = 0.4839\n",
    "\n",
    "\n",
    "voxel_dims = [2,2,2]\n",
    "cdef np.ndarray z = np.nan_to_num(np.array(nb.load(\"Results/MainEffect/Full/Volumes/Z/Other.nii\").get_fdata()))\n",
    "cdef float h = 0.2\n",
    "\n",
    "cdef ctfce_par(np.ndarray[np.float_t, ndim=3] invol, float h, float dh, int voxel_size, float E=0.6, int H=2):\n",
    "    cdef np.ndarray thresh \n",
    "    thresh = invol > h\n",
    "    cdef np.ndarray labels\n",
    "    labels, _ = ndimage.label(thresh)\n",
    "\n",
    "    cdef np.ndarray sizes\n",
    "\n",
    "    _, sizes = np.unique(labels, return_counts=True)\n",
    "    sizes[0] = 0\n",
    "    sizes = sizes * voxel_size\n",
    "\n",
    "    cdef np.ndarray mask = labels > 0\n",
    "    cdef np.ndarray szs = sizes[labels[mask]]\n",
    "    cdef np.ndarray update_vals\n",
    "    update_vals = np.multiply(np.power(h, H)*dh, np.power(szs, E))\n",
    "    return update_vals\n",
    "\n",
    "\n",
    "cdef float delta_t = np.max(z)/100\n",
    "cdef np.ndarray heights = np.arange(0, np.max(z), delta_t)\n",
    "\n",
    "start = tic()\n",
    "for h in heights:\n",
    "    ctfce_par(z, h, 0.4839, 8)\n",
    "print(toc(start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "retained-contemporary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print reached loop\n",
      "0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Buffer dtype mismatch, expected 'DTYPE_i' but got 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-238-be348ad1164e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cython'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from mytime import tic, toc\\nimport numpy as np\\nfrom scipy import ndimage\\nimport nibabel as nb\\ncimport numpy as np\\nfrom libcpp cimport bool\\n\\n\\nctypedef np.float_t DTYPE_f\\nctypedef np.int_t DTYPE_i\\n\\n\\ncdef np.ndarray voxel_dims = np.array([2,2,2])\\n\\ndef ctfce_par(np.ndarray[DTYPE_f, ndim=3] invol, float h, float dh, np.ndarray voxel_dims = np.array([2,2,2]), float E=0.6, int H=2):\\n    cdef np.ndarray[np.uint8_t, ndim = 3, cast=True] thresh = np.array(invol > h)\\n    cdef np.ndarray[DTYPE_i, ndim=3] labels\\n    \\n    labels, _ = ndimage.label(thresh)\\n    \\n    cdef np.ndarray[DTYPE_i, ndim=1] sizes\\n    \\n    _, sizes = np.unique(labels, return_counts=True)\\n    sizes[0] = 0\\n    sizes = sizes * np.prod(voxel_dims)\\n    \\n    cdef np.ndarray[np.uint8_t, ndim = 3, cast=True] mask = np.array(labels > 0)\\n    cdef np.ndarray[DTYPE_i, ndim=3] szs = sizes[labels[mask]]\\n    cdef np.ndarray[DTYPE_f, ndim=3] update_vals\\n    update_vals = np.multiply(np.power(h, H)*dh, np.power(szs, E))\\n    \\n    return update_vals\\n\\n\\ncdef np.ndarray z = np.array(nb.load(\"Results/MainEffect/Full/Volumes/Z/Other.nii\").get_fdata())\\nz = np.nan_to_num(z)\\n\\n\\ncdef float delta_t = np.max(z)/100\\ncdef np.ndarray heights = np.arange(0, np.max(z), delta_t)\\nprint(\"Print reached loop\")\\nfor h in heights:\\n    print(f\"{h}\")\\n    ctfce_par(z, h, delta_t)\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/envs/pyALE/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2397\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2398\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2399\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2400\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-119>\u001b[0m in \u001b[0;36mcython\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/envs/pyALE/lib/python3.9/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/envs/pyALE/lib/python3.9/site-packages/Cython/Build/IpythonMagic.py\u001b[0m in \u001b[0;36mcython\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_import_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    340\u001b[0m         spec = importlib.machinery.ModuleSpec(\n\u001b[1;32m    341\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m_cython_magic_b89628c5d7dfc9bf128bdf7fb29c1d34.pyx\u001b[0m in \u001b[0;36minit _cython_magic_b89628c5d7dfc9bf128bdf7fb29c1d34\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_cython_magic_b89628c5d7dfc9bf128bdf7fb29c1d34.pyx\u001b[0m in \u001b[0;36m_cython_magic_b89628c5d7dfc9bf128bdf7fb29c1d34.ctfce_par\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Buffer dtype mismatch, expected 'DTYPE_i' but got 'int'"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "from mytime import tic, toc\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import nibabel as nb\n",
    "cimport numpy as np\n",
    "from libcpp cimport bool\n",
    "\n",
    "\n",
    "ctypedef np.float_t DTYPE_f\n",
    "ctypedef np.int_t DTYPE_i\n",
    "\n",
    "\n",
    "cdef np.ndarray voxel_dims = np.array([2,2,2])\n",
    "\n",
    "def ctfce_par(np.ndarray[DTYPE_f, ndim=3] invol, float h, float dh, np.ndarray voxel_dims = np.array([2,2,2]), float E=0.6, int H=2):\n",
    "    cdef np.ndarray[np.uint8_t, ndim = 3, cast=True] thresh = np.array(invol > h)\n",
    "    cdef np.ndarray[DTYPE_i, ndim=3] labels\n",
    "    \n",
    "    labels, _ = ndimage.label(thresh)\n",
    "    \n",
    "    cdef np.ndarray[DTYPE_i, ndim=1] sizes\n",
    "    \n",
    "    _, sizes = np.unique(labels, return_counts=True)\n",
    "    sizes[0] = 0\n",
    "    sizes = sizes * np.prod(voxel_dims)\n",
    "    \n",
    "    cdef np.ndarray[np.uint8_t, ndim = 3, cast=True] mask = np.array(labels > 0)\n",
    "    cdef np.ndarray[DTYPE_i, ndim=3] szs = sizes[labels[mask]]\n",
    "    cdef np.ndarray[DTYPE_f, ndim=3] update_vals\n",
    "    update_vals = np.multiply(np.power(h, H)*dh, np.power(szs, E))\n",
    "    \n",
    "    return update_vals\n",
    "\n",
    "\n",
    "cdef np.ndarray z = np.array(nb.load(\"Results/MainEffect/Full/Volumes/Z/Other.nii\").get_fdata())\n",
    "z = np.nan_to_num(z)\n",
    "\n",
    "\n",
    "cdef float delta_t = np.max(z)/100\n",
    "cdef np.ndarray heights = np.arange(0, np.max(z), delta_t)\n",
    "print(\"Print reached loop\")\n",
    "for h in heights:\n",
    "    print(f\"{h}\")\n",
    "    ctfce_par(z, h, delta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "surface-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfce_par(invol, h, dh, voxel_dims=[2,2,2], E=0.6, H=2):\n",
    "    thresh = np.array(invol > h)\n",
    "    #look for suprathreshold clusters\n",
    "    labels, cluster_count = ndimage.label(thresh)\n",
    "    #calculate the size of the cluster; first voxel count, then multiplied with the voxel volume in mm\n",
    "    _ , sizes = np.unique(labels, return_counts=True)\n",
    "    sizes[0] = 0 \n",
    "    sizes = sizes * reduce(operator.mul, voxel_dims)\n",
    "    #mask out labeled areas to not perform tfce calculation on the whole brain\n",
    "    mask = labels > 0\n",
    "    szs = sizes[labels[mask]]\n",
    "    update_vals = np.multiply(np.power(h, H)*dh, np.power(szs, E))\n",
    "        \n",
    "    return update_vals, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "logical-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fitted-investigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         74 function calls (71 primitive calls) in 0.025 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "        1    0.013    0.013    0.013    0.013 {method 'sort' of 'numpy.ndarray' objects}\n",
       "        1    0.007    0.007    0.007    0.007 {built-in method scipy.ndimage._ni_label._label}\n",
       "        1    0.004    0.004    0.025    0.025 tfce_par.py:6(tfce_par)\n",
       "        1    0.001    0.001    0.014    0.014 arraysetops.py:310(_unique1d)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
       "        1    0.000    0.000    0.025    0.025 {built-in method builtins.exec}\n",
       "        1    0.000    0.000    0.000    0.000 morphology.py:124(generate_binary_structure)\n",
       "        1    0.000    0.000    0.007    0.007 measurements.py:44(label)\n",
       "      6/3    0.000    0.000    0.014    0.005 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:1686(indices)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
       "        1    0.000    0.000    0.000    0.000 function_base.py:1153(diff)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
       "        1    0.000    0.000    0.000    0.000 fromnumeric.py:52(_wrapfunc)\n",
       "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(iscomplexobj)\n",
       "        1    0.000    0.000    0.025    0.025 <string>:1(<module>)\n",
       "        1    0.000    0.000    0.014    0.014 arraysetops.py:138(unique)\n",
       "        1    0.000    0.000    0.000    0.000 fromnumeric.py:70(_wrapreduction)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\n",
       "        1    0.000    0.000    0.000    0.000 type_check.py:279(iscomplexobj)\n",
       "        1    0.000    0.000    0.014    0.014 <__array_function__ internals>:2(unique)\n",
       "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(nonzero)\n",
       "        1    0.000    0.000    0.000    0.000 fromnumeric.py:2355(all)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
       "        4    0.000    0.000    0.000    0.000 _asarray.py:110(asanyarray)\n",
       "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(diff)\n",
       "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(concatenate)\n",
       "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(all)\n",
       "        1    0.000    0.000    0.000    0.000 fromnumeric.py:1827(nonzero)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _functools.reduce}\n",
       "        2    0.000    0.000    0.000    0.000 _asarray.py:23(asarray)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}\n",
       "        1    0.000    0.000    0.000    0.000 fromnumeric.py:71(<dictcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
       "        1    0.000    0.000    0.000    0.000 arraysetops.py:125(_unpack_tuple)\n",
       "        1    0.000    0.000    0.000    0.000 index_tricks.py:748(__getitem__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
       "        1    0.000    0.000    0.000    0.000 fromnumeric.py:1823(_nonzero_dispatcher)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
       "        1    0.000    0.000    0.000    0.000 type_check.py:206(_is_type_dispatcher)\n",
       "        1    0.000    0.000    0.000    0.000 function_base.py:1149(_diff_dispatcher)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
       "        1    0.000    0.000    0.000    0.000 multiarray.py:143(concatenate)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 arraysetops.py:133(_unique_dispatcher)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
       "        1    0.000    0.000    0.000    0.000 fromnumeric.py:2350(_all_dispatcher)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%prun tfce_par(z, 0.3, 0.483)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "collected-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfce(z, sample_space):\n",
    "    \n",
    "    if z.shape != shape:\n",
    "        tmp = np.zeros(shape)\n",
    "        tmp[tuple(sample_space)] = z\n",
    "        z = tmp\n",
    "    \n",
    "    lc = np.min(sample_space, axis=1)\n",
    "    uc = np.max(sample_space, axis=1)  \n",
    "    z = z[lc[0]:uc[0],lc[1]:uc[1],lc[2]:uc[2]]\n",
    "    \n",
    "    delta_t = np.max(z)/100\n",
    "    \n",
    "    tmp = np.zeros(z.shape)\n",
    "    # calculate tfce values using the parallelized function\n",
    "    vals, masks = zip(*Parallel(n_jobs=-1)\n",
    "                     (delayed(tfce_par)(invol=z, h=h, dh=delta_t) for h in np.arange(0, np.max(z), delta_t)))\n",
    "    # Parallelization makes it necessary to integrate the results afterwards\n",
    "    # Each repition creats it's own mask and an amount of values corresponding to that mask\n",
    "    for i in range(len(vals)):\n",
    "        tmp[masks[i]] += vals[i]\n",
    "        \n",
    "    tfce = np.zeros(shape)\n",
    "    tfce[lc[0]:uc[0],lc[1]:uc[1],lc[2]:uc[2]] = tmp\n",
    "    \n",
    "    return tfce\n",
    "\n",
    "\n",
    "\n",
    "def compute_null_cutoffs(s0, sample_space, num_peaks, kernels, step=10000, thresh=0.001, target_n=None,\n",
    "                          hx_conv=None, bin_edges=None, bin_centers=None, tfce=None):\n",
    "    if target_n:\n",
    "        s0 = np.random.permutation(s0)\n",
    "        s0 = s0[:target_n]\n",
    "    # compute ALE values based on random peak locations sampled from a give sample_space\n",
    "    # sample space could be all grey matter or only foci reported in brainmap\n",
    "    null_ma, null_ale = compute_null_ale(s0, sample_space, num_peaks, kernels)\n",
    "    # Peak ALE threshold\n",
    "    null_max_ale = np.max(null_ale)\n",
    "    if hx_conv is None:\n",
    "        s0 = list(range(len(s0)))\n",
    "        null_hx = compute_hx(s0, null_ma, bin_edges)\n",
    "        hx_conv = compute_hx_conv(s0, null_hx, bin_centers, step)\n",
    "    null_z = compute_z(null_ale, hx_conv, step)\n",
    "    # Cluster level threshold\n",
    "    null_max_cluster = compute_cluster(null_z, thresh, sample_space)\n",
    "    if tfce:\n",
    "        tfce = compute_tfce(null_z, sample_space)\n",
    "        # TFCE threshold\n",
    "        null_max_tfce = np.max(tfce)\n",
    "        return null_ale, null_max_ale, null_max_cluster, null_max_tfce\n",
    "        \n",
    "    return null_max_ale, null_max_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "collaborative-lesson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "import time\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "\n",
    "def compute_ma():\n",
    "    cdef np.ndarray pad_shape = np.array([121,139,121])\n",
    "    cdef np.ndarray data = np.zeros(pad_shape)\n",
    "    cdef np.ndarray null_peaks = np.array([sample_space[:,np.random.randint(0,sample_space.shape[1], num_peaks[i])].T for i in s0], dtype=object)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
