{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import nibabel as nb\n",
    "import math as m\n",
    "import pickle\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from compile_studies import compile_studies\n",
    "from tfce import tfce\n",
    "from scipy.io import loadmat\n",
    "from simulate_noise import simulate_noise\n",
    "\n",
    "cwd = os.getcwd()\n",
    "raw_folder = cwd + '/DataRaw/'\n",
    "pickle_folder = cwd + '/DataPickle/'\n",
    "mask_folder = cwd + '/MaskenEtc/'\n",
    "\n",
    "'''filename = askopenfilename()\n",
    "df = pd.read_excel(filename, engine='openpyxl', header=None)'''\n",
    "\n",
    "df = pd.read_excel(raw_folder + 'Metastocalculate.xlsx', engine='openpyxl', header=None)\n",
    "with open(pickle_folder + 'experiments.pickle', 'rb') as f:\n",
    "    experiments, tasks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other : 19experiments; average of 22.263157894736842 subjects per experiment\n",
      "Cwclassic : 37experiments; average of 25.756756756756758 subjects per experiment\n",
      "Cwvariant : 21experiments; average of 26.333333333333332 subjects per experiment\n",
      "CwIvsC : 58experiments; average of 25.96551724137931 subjects per experiment\n",
      "CwIvsN : 41experiments; average of 22.21951219512195 subjects per experiment\n",
      "CwIvsNwords : 17experiments; average of 22.235294117647058 subjects per experiment\n",
      "CwIvsNsymbolsletters : 23experiments; average of 22.304347826086957 subjects per experiment\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    if row[0] == 'M': #Main Effect Analysis\n",
    "        s0 = compile_studies(df, index, experiments, tasks)\n",
    "        if len(s0) >= 12:\n",
    "            category = df.iloc[index, 1]\n",
    "            mean_subjects = experiments.iloc[s0].Subjects.mean()\n",
    "            print(category + ' : ' + str(len(s0)) + 'experiments; average of {mean} subjects per experiment'.format(mean=mean_subjects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ComputeALEtfce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other - loading Foci\n",
      "Other - loading ALE\n",
      "Other - loading null PDF\n",
      "Other - loading p-values\n"
     ]
    }
   ],
   "source": [
    "s0 = compile_studies(df, 0, experiments, tasks)\n",
    "experiments = experiments.loc[s0]\n",
    "study = 'Other'\n",
    "\n",
    "template = nb.load(mask_folder + \"Grey10.nii\")\n",
    "template_data = template.get_fdata()\n",
    "template_shape = template_data.shape\n",
    "pad_tmp_shape = [value+30 for value in template_shape]\n",
    "\n",
    "\n",
    "prior = np.zeros(template_shape, dtype=bool)\n",
    "prior[template_data > 0.1] = 1\n",
    "uc = 0.001\n",
    "c = str(uc)[2:]\n",
    "eps = np.finfo(float).eps\n",
    "\n",
    "num_exp = len(s0)\n",
    "mb = 1\n",
    "for i in s0:\n",
    "    mb = mb*(1-np.max(experiments.at[i, 'Kernel']))\n",
    "\n",
    "bin_edge = np.arange(0.00005,1-mb+0.001,0.0001)\n",
    "bin_center = np.arange(0,1-mb+0.001,0.0001)\n",
    "step = 1/0.0001\n",
    "\n",
    "folders_req = ['Volumes', 'NullDistributions', 'VolumesZ', 'VolumesTFCE', 'Results', 'Images', 'Foci']\n",
    "folders_req_imgs = ['Foci', 'ALE', 'TFCE']\n",
    "\n",
    "try:\n",
    "    os.mkdir('ALE')\n",
    "    for folder in folders_req:\n",
    "        os.mkdir('ALE/' + folder)\n",
    "        if folder == 'Images':\n",
    "            for sub_folder in folders_req_imgs:\n",
    "                os.mkdir('ALE/Images/' + sub_folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "if isfile(cwd + '/ALE/Foci/' + study + '.nii'):\n",
    "    print('{} - loading Foci'.format(study))\n",
    "    foci_arr = nb.load(cwd + '/ALE/Foci/' + study + '.nii').get_fdata()\n",
    "else:\n",
    "    print('{} - illustrate Foci'.format(study))\n",
    "    \n",
    "    foci_arr = np.zeros(template_shape)\n",
    "    nested_list = [experiments.XYZ[i].T[:,:3].tolist() for i in s0]\n",
    "    flat_list = np.array([item for sublist in nested_list for item in sublist])\n",
    "    foci_arr[tuple(flat_list.T)] += 1\n",
    "    foci_arr[~prior] = np.nan \n",
    "    ni_img = nb.Nifti1Image(foci_arr, template.affine)\n",
    "    nb.save(ni_img, cwd + '/ALE/Foci/' + study + '.nii')\n",
    "    \n",
    "\n",
    "\n",
    "if isfile(cwd + '/ALE/NullDistributions/' + study + '.pickle'):\n",
    "    print('{} - loading ALE'.format(study))\n",
    "    print('{} - loading null PDF'.format(study))\n",
    "    ale_arr = nb.load(cwd + '/ALE/Volumes/' + study + '.nii').get_fdata()\n",
    "    ale_arr = np.nan_to_num(ale_arr)\n",
    "    with open(cwd + '/ALE/NullDistributions/' + study + '.pickle', 'rb') as f:\n",
    "            ale_hist, last_used, c_null = pickle.load(f)\n",
    "else:\n",
    "    print('{} - computing ALE'.format(study))\n",
    "    \n",
    "    ale_arr = np.ones(template_shape)\n",
    "    hx = np.zeros((len(s0),len(bin_edge)))\n",
    "    for c, i in enumerate(s0):\n",
    "        data = np.zeros(pad_tmp_shape)\n",
    "        for ii in range(experiments.at[i, 'Peaks']):\n",
    "            coords = experiments.XYZ[i].T[:,:3][ii]\n",
    "            x_range = (coords[0],coords[0]+31)\n",
    "            y_range = (coords[1],coords[1]+31)\n",
    "            z_range = (coords[2],coords[2]+31)\n",
    "            data[x_range[0]:x_range[1], y_range[0]:y_range[1], z_range[0]:z_range[1]] = \\\n",
    "            np.maximum(data[x_range[0]:x_range[1], y_range[0]:y_range[1], z_range[0]:z_range[1]],\n",
    "                       experiments.at[i, 'Kernel'])\n",
    "        data = data[15:data.shape[0]-15,15:data.shape[1]-15, 15:data.shape[2]-15]\n",
    "        bin_idxs, counts = np.unique(np.digitize(data[prior], bin_edge),return_counts=True)\n",
    "        hx[c,bin_idxs] = counts\n",
    "        ale_arr = np.multiply(ale_arr, 1-data)\n",
    "\n",
    "    ale_arr = 1-ale_arr\n",
    "    ale_arr[~prior] = np.nan\n",
    "    \n",
    "    #Save ALE scores in Nifti\n",
    "    ni_img = nb.Nifti1Image(ale_arr, template.affine)\n",
    "    nb.save(ni_img, cwd + '/ALE/Volumes/' + study + '.nii')\n",
    "\n",
    "    \n",
    "    print('{} - permutation-null PDF'.format(study))\n",
    "    step = 1/np.mean(np.diff(bin_center))\n",
    "    ale_hist = hx[0,:]\n",
    "    for i in range(1,len(s0)):\n",
    "        v1 = ale_hist\n",
    "        v2 = hx[i,:]\n",
    "\n",
    "        da1 = np.where(v1 > 0)[0]\n",
    "        da2 = np.where(v2 > 0)[0]\n",
    "\n",
    "        v1 = ale_hist/np.sum(v1)\n",
    "        v2 = hx[i,:]/np.sum(v2)\n",
    "\n",
    "        ale_hist = np.zeros((len(bin_center),))\n",
    "        for i in range(len(da2)):\n",
    "            p = v2[da2[i]]*v1[da1]\n",
    "            score = 1-(1-bin_center[da2[i]])*(1-bin_center[da1])\n",
    "            ale_bin = np.round(score*step).astype(int)\n",
    "            ale_hist[ale_bin] = np.add(ale_hist[ale_bin], p)\n",
    "\n",
    "    last_used = np.where(ale_hist>0)[0][-1]\n",
    "    c_null = np.flip(np.cumsum(np.flip(ale_hist[:last_used+1])))\n",
    "\n",
    "    pickle_object = (ale_hist, last_used, c_null)\n",
    "    with open(cwd + '/ALE/NullDistributions/' + study + '.pickle', \"wb\") as f:\n",
    "        pickle.dump(pickle_object, f)\n",
    "\n",
    "if isfile(cwd + '/ALE/VolumesTFCE/' + study + '.nii'):\n",
    "    print('{} - loading p-values'.format(study))\n",
    "    \n",
    "    z_arr = nb.load(cwd + '/ALE/VolumesZ/' + study + '.nii').get_fdata()\n",
    "    z_arr = np.nan_to_num(z_arr)\n",
    "    \n",
    "    tfce_arr = nb.load(cwd + '/ALE/VolumesTFCE/' + study + '.nii').get_fdata()\n",
    "else:\n",
    "    print('{} - computing p-values'.format(study))\n",
    "    \n",
    "    ale_step = np.round(ale_arr*step)\n",
    "    palette, index = np.unique(ale_step, return_inverse=True)\n",
    "    index = palette[index].astype(int)\n",
    "    p = c_null[index].reshape(ale_step.shape)\n",
    "    p[p < eps] = eps\n",
    "    z_arr = norm.ppf(1-p)\n",
    "    \n",
    "    tfce_arr = tfce(invol=z_arr, voxel_dims=template.header.get_zooms())\n",
    "    tfce_arr[~prior] = np.nan\n",
    "    \n",
    "    tfce_img = nb.Nifti1Image(tfce_arr, template.affine)\n",
    "    nb.save(tfce_img, cwd + '/ALE/VolumesTFCE/' + study + '.nii')\n",
    "    \n",
    "    z_arr[~prior] = np.nan\n",
    "    z_img = nb.Nifti1Image(z_arr, template.affine)\n",
    "    nb.save(z_img, cwd + '/ALE/VolumesZ/' + study + '.nii')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_peaks = experiments.loc[:,'Peaks']\n",
    "kernels = experiments.loc[:,'Kernel']\n",
    "\n",
    "from scipy.io import loadmat\n",
    "permSpace5 = loadmat(\"MaskenEtc/permSpace5.mat\")\n",
    "\n",
    "sample_space = permSpace5[\"allXYZ\"]\n",
    "delta_t = np.max(z_arr)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for ale calc:0.1407351699999999\n",
      "time taken for p-value calc:0.043309320000000096\n",
      "time taken for tfce calc:3.028588858\n",
      "time taken for ale calc:0.09849789400000031\n",
      "time taken for p-value calc:0.03796099099999939\n",
      "time taken for tfce calc:2.992041489\n",
      "time taken for ale calc:0.09863261599999973\n",
      "time taken for p-value calc:0.03730211400000005\n",
      "time taken for tfce calc:3.0731898189999995\n",
      "time taken for ale calc:0.0996185900000004\n",
      "time taken for p-value calc:0.0386036359999995\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9dc450a3bc4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     simulate_noise(sample_space = sample_space,\n\u001b[0m\u001b[1;32m      3\u001b[0m                    \u001b[0ms0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                    \u001b[0mnum_peaks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_peaks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    \u001b[0mkernels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IDrive-Sync/sync_Documents/PhD/Code/ALE/pyALE/simulate_noise.py\u001b[0m in \u001b[0;36msimulate_noise\u001b[0;34m(sample_space, s0, num_peaks, kernels, c_null, eps, uc, tfce_params, pad_tmp_shape, voxel_dims, step)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mstarttime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# TFCE threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     tfce_arr = tfce(invol=z,\n\u001b[0m\u001b[1;32m     56\u001b[0m                     \u001b[0mvoxel_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvoxel_dims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                     \u001b[0mdh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtfce_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IDrive-Sync/sync_Documents/PhD/Code/ALE/pyALE/tfce.py\u001b[0m in \u001b[0;36mtfce\u001b[0;34m(invol, voxel_dims, dh, E, H, negative)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m#calculate the size of the cluster; first voxel count, then multiplied with the voxel volume in mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0msizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_count\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0msizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msizes\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoxel_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/scipy/ndimage/measurements.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(input, labels, index)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \"\"\"\n\u001b[0;32m--> 587\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msum_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/scipy/ndimage/measurements.py\u001b[0m in \u001b[0;36msum_labels\u001b[0;34m(input, labels, index)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \"\"\"\n\u001b[0;32m--> 631\u001b[0;31m     \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/scipy/ndimage/measurements.py\u001b[0m in \u001b[0;36m_stats\u001b[0;34m(input, labels, index, centered)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# labels are an integer type allowed by bincount, and there aren't too\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# many, so call bincount directly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0msums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcentered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbincount\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    simulate_noise(sample_space = sample_space,\n",
    "                   s0 = s0,\n",
    "                   num_peaks = num_peaks,\n",
    "                   kernels = kernels,\n",
    "                   c_null = c_null,\n",
    "                   tfce_params = [delta_t, 0.6, 2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
