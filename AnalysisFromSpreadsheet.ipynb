{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import nibabel as nb\n",
    "import math as m\n",
    "import pickle\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from compile_studies import compile_studies\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "raw_folder = cwd + '/DataRaw/'\n",
    "pickle_folder = cwd + '/DataPickle/'\n",
    "mask_folder = cwd + '/MaskenEtc/'\n",
    "\n",
    "'''filename = askopenfilename()\n",
    "df = pd.read_excel(filename, engine='openpyxl', header=None)'''\n",
    "\n",
    "df = pd.read_excel(raw_folder + 'Metastocalculate.xlsx', engine='openpyxl', header=None)\n",
    "with open(pickle_folder + 'experiments.pickle', 'rb') as f:\n",
    "    experiments, tasks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other : 19experiments; average of 22.263157894736842 subjects per experiment\n",
      "Cwclassic : 37experiments; average of 25.756756756756758 subjects per experiment\n",
      "Cwvariant : 21experiments; average of 26.333333333333332 subjects per experiment\n",
      "CwIvsC : 58experiments; average of 25.96551724137931 subjects per experiment\n",
      "CwIvsN : 41experiments; average of 22.21951219512195 subjects per experiment\n",
      "CwIvsNwords : 17experiments; average of 22.235294117647058 subjects per experiment\n",
      "CwIvsNsymbolsletters : 23experiments; average of 22.304347826086957 subjects per experiment\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    if row[0] == 'M': #Main Effect Analysis\n",
    "        s0 = compile_studies(df, index, experiments, tasks)\n",
    "        if len(s0) >= 12:\n",
    "            category = df.iloc[index, 1]\n",
    "            mean_subjects = experiments.iloc[s0].Subjects.mean()\n",
    "            print(category + ' : ' + str(len(s0)) + 'experiments; average of {mean} subjects per experiment'.format(mean=mean_subjects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ComputeALEtfce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = compile_studies(df, 0, experiments, tasks)\n",
    "experiments = experiments.loc[s0]\n",
    "study = 'Other'\n",
    "\n",
    "template = nb.load(mask_folder + \"Grey10.nii\")\n",
    "template_data = template.get_fdata()\n",
    "template_shape = template_data.shape\n",
    "\n",
    "prior = np.zeros(template_shape, dtype=bool)\n",
    "prior[template_data > 0.1] = 1\n",
    "uc = 0.001\n",
    "c = str(uc)[2:]\n",
    "\n",
    "num_exp = len(s0)\n",
    "mb = 1\n",
    "for i in s0:\n",
    "    mb = mb*(1-np.max(experiments.at[i, 'Kernel']))\n",
    "\n",
    "bin_edge = np.arange(0.00005,1-mb+0.001,0.0001)\n",
    "bin_center = np.arange(0,1-mb+0.001,0.0001)\n",
    "step = 1/0.0001\n",
    "\n",
    "folders_req = ['Volumes', 'NullDistributions', 'VolumesZ', 'VolumesTFCE', 'Results', 'Images', 'Foci']\n",
    "folders_req_imgs = ['Foci', 'ALE', 'TFCE']\n",
    "\n",
    "try:\n",
    "    os.mkdir('ALE')\n",
    "    for folder in folders_req:\n",
    "        if folder == 'Images':\n",
    "            for sub_folder in folders_req_imgs:\n",
    "                os.mkdir('ALE/Images/' + sub_folder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "\n",
    "if not isfile(cwd + '/ALE/Foci/' + study + '.nii'):\n",
    "    print('{} - illustrate Foci'.format(study))\n",
    "    \n",
    "    arr = np.zeros(template_shape)\n",
    "    nested_list = [experiments.XYZ[i].T[:,:3].tolist() for i in s0]\n",
    "    flat_list = np.array([item for sublist in nested_list for item in sublist])\n",
    "    arr[tuple(flat_list.T)] += 1\n",
    "    arr[~prior] = np.nan \n",
    "    ni_img = nb.Nifti1Image(arr, template.affine)\n",
    "    nb.save(ni_img, cwd + '/ALE/Foci/' + study + '.nii')\n",
    "    \n",
    "\n",
    "\n",
    "if not isfile(cwd + '/ALE/NullDistributions/' + study + '.pickle'):\n",
    "    print('{} - computing ALE'.format(study))\n",
    "    \n",
    "    arr_shape = [value+30 for value in template_shape]\n",
    "    \n",
    "    arr_ALE = np.ones(template_shape)\n",
    "    hx = np.zeros((len(s0),len(bin_edge)))\n",
    "    for c, i in enumerate(s0):\n",
    "        data = np.zeros(arr_shape)\n",
    "        for ii in range(experiments.at[i, 'Peaks']):\n",
    "            coords = experiments.XYZ[i].T[:,:3][ii]\n",
    "            x_range = (coords[0],coords[0]+31)\n",
    "            y_range = (coords[1],coords[1]+31)\n",
    "            z_range = (coords[2],coords[2]+31)\n",
    "            data[x_range[0]:x_range[1], y_range[0]:y_range[1], z_range[0]:z_range[1]] = \\\n",
    "            np.maximum(data[x_range[0]:x_range[1], y_range[0]:y_range[1], z_range[0]:z_range[1]],\n",
    "                       experiments.at[i, 'Kernel'])\n",
    "        data = data[15:data.shape[0]-15,15:data.shape[1]-15, 15:data.shape[2]-15]\n",
    "        bin_idxs, counts = np.unique(np.digitize(data[prior], bin_edge),return_counts=True)\n",
    "        hx[c,bin_idxs] = counts\n",
    "        arr_ALE = np.multiply(arr_ALE, 1-data)\n",
    "\n",
    "    arr_ALE = 1-arr_ALE\n",
    "    arr_ALE[~prior] = np.nan\n",
    "    \n",
    "    if not isfile(cwd + '/ALE/Volumes/' + study + '.nii'):\n",
    "        ni_img = nb.Nifti1Image(arr_ALE, template.affine)\n",
    "        nb.save(ni_img, cwd + '/ALE/Volumes/' + study + '.nii')\n",
    "\n",
    "    \n",
    "    print('{} - permutation-null PDF'.format(study))\n",
    "    step = 1/np.mean(np.diff(bin_center))\n",
    "    ale_hist = hx[0,:]\n",
    "    for i in range(1,len(s0)):\n",
    "        v1 = ale_hist\n",
    "        v2 = hx[i,:]\n",
    "\n",
    "        da1 = np.where(v1 > 0)[0]\n",
    "        da2 = np.where(v2 > 0)[0]\n",
    "\n",
    "        v1 = ale_hist/np.sum(v1)\n",
    "        v2 = hx[i,:]/np.sum(v2)\n",
    "\n",
    "        ale_hist = np.zeros((len(bins),))\n",
    "        for i in range(len(da2)):\n",
    "            p = v2[da2[i]]*v1[da1]\n",
    "            score = 1-(1-bin_center[da2[i]])*(1-bin_center[da1])\n",
    "            ale_bin = np.round(score*step).astype(int)\n",
    "            ale_hist[ale_bin] = np.add(ale_hist[ale_bin], p)\n",
    "\n",
    "    last_used = np.where(ale_hist>0)[0][-1]\n",
    "    c_null = np.flip(np.cumsum(np.flip(ale_hist[:last_used])))\n",
    "\n",
    "    pickle_object = (ale_hist, last_used, c_null)\n",
    "    with open(cwd + '/ALE/NullDistributions/' + study + '.pickle', \"wb\") as f:\n",
    "        pickle.dump(pickle_object, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myround(val):\n",
    "    \"Fix pythons round\"\n",
    "    d,v = m.modf(val)\n",
    "    if d==0.5:\n",
    "        val += 0.000000001\n",
    "    return round(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vround = np.vectorize(myround)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other - computing p-values\n"
     ]
    }
   ],
   "source": [
    "if not isfile(cwd + '/ALE/VolumesZ/' + study + '.nii'):\n",
    "    print('{} - computing p-values'.format(study))\n",
    "    with open(cwd + '/ALE/NullDistributions/' + study + '.pickle', 'rb') as f:\n",
    "        ale_hist, last_used, c_null = pickle.load(f)\n",
    "    ale_arr = nb.load(cwd + '/ALE/Volumes/' + study + '.nii').get_fdata()\n",
    "    ale_arr = np.nan_to_num(ale_arr)\n",
    "    \n",
    "    ale_step = vround(ale_arr*step)\n",
    "    palette, index = np.unique(ale_step, return_inverse=True)\n",
    "    p = c_null[index].reshape(ale_step.shape)\n",
    "    z = norm.ppf(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3688894.283966299"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
