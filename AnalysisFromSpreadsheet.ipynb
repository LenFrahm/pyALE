{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from compute_ale import compute_ale\n",
    "from compile_studies import compile_studies\n",
    "%matplotlib inline\n",
    "\n",
    "cwd = os.getcwd()\n",
    "raw_folder = cwd + '/DataRaw/'\n",
    "pickle_folder = cwd + '/DataPickle/'\n",
    "\n",
    "'''filename = askopenfilename()\n",
    "df = pd.read_excel(filename, engine='openpyxl', header=None)'''\n",
    "\n",
    "df = pd.read_excel(raw_folder + 'Metastocalculate.xlsx', engine='openpyxl', header=None)\n",
    "with open(pickle_folder + 'experiments.pickle', 'rb') as f:\n",
    "    experiments, tasks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other : 19experiments; average of 22.263157894736842 subjects per experiment\n",
      "Cwclassic : 37experiments; average of 25.756756756756758 subjects per experiment\n",
      "Cwvariant : 21experiments; average of 26.333333333333332 subjects per experiment\n",
      "CwIvsC : 58experiments; average of 25.96551724137931 subjects per experiment\n",
      "CwIvsN : 41experiments; average of 22.21951219512195 subjects per experiment\n",
      "CwIvsNwords : 17experiments; average of 22.235294117647058 subjects per experiment\n",
      "CwIvsNsymbolsletters : 23experiments; average of 22.304347826086957 subjects per experiment\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    if row[0] == 'M': #Main Effect Analysis\n",
    "        s0 = compile_studies(df, index, experiments, tasks)\n",
    "        if len(s0) >= 12:\n",
    "            category = df.iloc[index, 1]\n",
    "            mean_subjects = experiments.iloc[s0].Subjects.mean()\n",
    "            print(category + ' : ' + str(len(s0)) + 'experiments; average of {mean} subjects per experiment'.format(mean=mean_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = compile_studies(df, 0, experiments, tasks)\n",
    "experiments = experiments.loc[s0].reset_index(drop=True)\n",
    "s_index = s0\n",
    "s0 = list(range(len(s0)))\n",
    "study = 'Other'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other - loading Foci\n",
      "Other - loading ALE\n",
      "Other - loading null PDF\n",
      "Other - loading p-values\n",
      "Other - loading noise\n",
      "Other - done!\n"
     ]
    }
   ],
   "source": [
    "compute_ale(s0, experiments, study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nb\n",
    "from scipy import ndimage\n",
    "\n",
    "cwd = os.getcwd()\n",
    "mask_folder = cwd + \"/MaskenEtc/\"\n",
    "try:\n",
    "    os.mkdir(cwd + \"/ALE/Contribution\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "template = nb.load(mask_folder + \"Grey10.nii\")\n",
    "template_data = template.get_fdata()\n",
    "template_shape = template_data.shape\n",
    "pad_tmp_shape = [value+30 for value in template_shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data = np.empty((len(s0), template_shape[0], template_shape[1], template_shape[2]))\n",
    "for i in s0:\n",
    "    data = np.zeros(pad_tmp_shape)\n",
    "    for ii in range(experiments.at[i, 'Peaks']):\n",
    "        coords = experiments.XYZ[i].T[:,:3][ii]\n",
    "        x_range = (coords[0],coords[0]+31)\n",
    "        y_range = (coords[1],coords[1]+31)\n",
    "        z_range = (coords[2],coords[2]+31)\n",
    "        data[x_range[0]:x_range[1], y_range[0]:y_range[1], z_range[0]:z_range[1]] = \\\n",
    "        np.maximum(data[x_range[0]:x_range[1], y_range[0]:y_range[1], z_range[0]:z_range[1]],\n",
    "                   experiments.at[i, 'Kernel'])\n",
    "    exp_data[i,:,:,:] = (data[15:data.shape[0]-15,15:data.shape[1]-15, 15:data.shape[2]-15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_methods = [\"TFCE\", \"FWE\", \"cFWE\"]\n",
    "\n",
    "for corr_method in corr_methods:\n",
    "    txt = open(cwd + \"/ALE/Contribution/\" + study + \"_\" + corr_method + \".txt\", \"w+\")\n",
    "    txt.write(\"\\nStarting with {}! \\n\".format(study))\n",
    "    txt.write(\"\\n{}: {} experiments; {} unique subjects (average of {:4.1f} per experiment) \\n\".format(study, len(s0), experiments.Subjects.sum(), experiments.Subjects.mean()))\n",
    "\n",
    "    if isfile(cwd + \"/ALE/Results/{}_{}05.nii\".format(study, corr_method)):\n",
    "        results = nb.load(cwd + \"/ALE/Results/{}_{}05.nii\".format(study, corr_method)).get_fdata()\n",
    "        if results.any() > 0:\n",
    "            labels, cluster_count = ndimage.label(results)\n",
    "            ale = nb.load(cwd + \"/ALE/Volumes/{}.nii\".format(study))\n",
    "            for label in np.unique(labels[labels > 0]):\n",
    "                clust_ind = np.vstack(np.where(labels == label))\n",
    "                clust_size = clust_ind.shape[1]\n",
    "                center = np.median(np.dot(template.affine, np.pad(clust_ind, ((0,1),(0,0)), constant_values=1)), axis=1)\n",
    "                if clust_ind[0].size > 5:\n",
    "                    txt.write(\"\\n\\nCluster {}: {} voxel [Center: {}/{}/{}] \\n\".format(label, clust_size, int(center[0]), int(center[1]), int(center[2])))\n",
    "\n",
    "                    ax = exp_data[:, clust_ind[0], clust_ind[1], clust_ind[2]]\n",
    "                    axf = 1-np.prod(1-ax, axis=0)\n",
    "                    axr = np.array([1-np.prod(1-np.delete(ax, i, axis=0), axis=0) for i in s0])\n",
    "                    wig = np.array([np.sum(exp_data[i][tuple(clust_ind)]) for i in s0])\n",
    "                    xsum = np.array([[wig[i], 100*wig[i]/clust_size, 100*(1-np.mean(np.divide(axr[i,:], axf))), np.max(100*(1-np.divide(axr[i,:], axf)))] for i in s0])\n",
    "                    xsum[:,2] = xsum[:,2]/np.sum(xsum[:,2])*100\n",
    "\n",
    "                    for i in s0:\n",
    "                        if xsum[i, 2]>.1 or xsum[i, 3]>5:\n",
    "\n",
    "                            stx = list(\" \" * (experiments.Author.str.len().max() + 2))\n",
    "                            stx[0:len(experiments.Author[i])] = experiments.Author[i]\n",
    "                            stx = \"\".join(stx)\n",
    "                            txt.write(\"{}\\t{:.3f}\\t{:.3f}\\t{:.2f}\\t{:.2f}\\t({})\\n\".format(stx,xsum[i,0],xsum[i,1],xsum[i,2],xsum[i,3],experiments.at[i, \"Subjects\"],))\n",
    "\n",
    "\n",
    "                    txt.write(\"\\n\\n\")\n",
    "\n",
    "                    for i in range(tasks.shape[0]):\n",
    "                        stx = list(\" \" * (tasks.Name.str.len().max()))\n",
    "                        stx[0:len(tasks.Name[i])] = tasks.Name[i]\n",
    "                        stx = \"\".join(stx)\n",
    "                        mask = [s in tasks.ExpIndex[i] for s in s_index]\n",
    "                        if mask.count(True) > 1:\n",
    "                            xsum_tmp = np.sum(xsum[mask], axis=0)\n",
    "                            txt.write(\"{}\\t{:.3f}\\t{:.3f}\\t{:.2f}\\t \\n\".format(stx,xsum_tmp[0],xsum_tmp[1], xsum_tmp[2]))\n",
    "                        elif mask.count(True) == 1:\n",
    "                            txt.write(\"{}\\t{:.3f}\\t{:.3f}\\t{:.2f}\\t \\n\".format(stx,xsum[mask][0,0],xsum[mask][0,1], xsum[mask][0,2]))\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "            txt.write(\"\\nDone with {}!\".format(corr_method))\n",
    "            txt.close()\n",
    "        else:\n",
    "            txt.write(\"No significant clusters in {}!\".format(corr_method))\n",
    "            txt.close()\n",
    "    else:\n",
    "        txt.write(\"Could not find {} results for {}!\".format(corr_method, study))\n",
    "        txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
